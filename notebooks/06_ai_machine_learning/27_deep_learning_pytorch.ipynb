{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be9a80e7",
   "metadata": {},
   "source": [
    "# Deep Learning with PyTorch\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this lesson, you will be able to:\n",
    "- Understand what neural networks are and how they work\n",
    "- Create and train neural networks with PyTorch\n",
    "- Build models for image classification\n",
    "- Understand tensors and automatic differentiation\n",
    "\n",
    "## Core Concepts\n",
    "- **Neural Network**: Computer model inspired by how brain neurons work\n",
    "- **Tensor**: Multi-dimensional array (like advanced spreadsheet)\n",
    "- **Layer**: Building block that processes and transforms data\n",
    "- **Training**: Process of teaching the network to make good predictions\n",
    "- **Gradient**: How much to adjust weights to improve performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae356a9c",
   "metadata": {},
   "source": [
    "## 1. PyTorch Basics and Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e51006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Tensors: PyTorch's data structure (like NumPy arrays but for deep learning)\n",
    "print(\"ðŸ”¢ TENSORS: Building blocks of neural networks\")\n",
    "\n",
    "# Create tensors\n",
    "data_1d = torch.tensor([1.0, 2.0, 3.0, 4.0])\n",
    "data_2d = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "random_data = torch.randn(3, 4)  # Random 3x4 tensor\n",
    "\n",
    "print(f\"1D tensor: {data_1d}\")\n",
    "print(f\"2D tensor:\\n{data_2d}\")\n",
    "print(f\"Random tensor shape: {random_data.shape}\")\n",
    "\n",
    "# Tensor operations (similar to NumPy)\n",
    "print(f\"\\nTensor math:\")\n",
    "print(f\"Add: {data_1d + 1}\")\n",
    "print(f\"Multiply: {data_1d * 2}\")\n",
    "print(f\"Square: {data_1d ** 2}\")\n",
    "\n",
    "# Gradients: How neural networks learn\n",
    "print(f\"\\nâš¡ GRADIENTS: How learning happens\")\n",
    "\n",
    "# Create tensor that tracks gradients\n",
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "y = x ** 2 + 3 * x + 1  # Simple function\n",
    "\n",
    "# Compute gradient (derivative)\n",
    "y.backward()\n",
    "print(f\"x = {x.item()}\")\n",
    "print(f\"y = xÂ² + 3x + 1 = {y.item()}\")\n",
    "print(f\"Gradient (dy/dx) = {x.grad.item()}\")\n",
    "print(f\"Expected gradient = 2x + 3 = {2 * x.item() + 3}\")\n",
    "\n",
    "# Real example: Predicting house prices with tensors\n",
    "print(f\"\\nðŸ  PRACTICAL EXAMPLE: House price prediction\")\n",
    "\n",
    "# Sample data: [size, bedrooms] -> price\n",
    "house_features = torch.tensor([[1200, 2], [1800, 3], [2400, 4], [1600, 3]], dtype=torch.float32)\n",
    "house_prices = torch.tensor([[250000], [350000], [480000], [320000]], dtype=torch.float32)\n",
    "\n",
    "print(f\"House features shape: {house_features.shape}\")\n",
    "print(f\"House prices shape: {house_prices.shape}\")\n",
    "print(f\"Sample house: {house_features[0]} sqft â†’ ${house_prices[0].item():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005e174b",
   "metadata": {},
   "source": [
    "## 2. Building Your First Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f07fce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple neural network\n",
    "print(\"ðŸ§  BUILDING A NEURAL NETWORK\")\n",
    "\n",
    "class SimpleNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNetwork, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.layer2 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "# Create network for house price prediction\n",
    "model = SimpleNetwork(input_size=2, hidden_size=10, output_size=1)\n",
    "print(f\"Model created: {model}\")\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()  # For regression (predicting numbers)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "print(f\"Loss function: Mean Squared Error\")\n",
    "print(f\"Optimizer: Adam (learning rate = 0.01)\")\n",
    "\n",
    "# Training the network\n",
    "print(f\"\\nðŸŽ¯ TRAINING THE NETWORK\")\n",
    "\n",
    "# Normalize features (important for neural networks)\n",
    "house_features_norm = (house_features - house_features.mean(dim=0)) / house_features.std(dim=0)\n",
    "house_prices_norm = house_prices / 1000  # Scale prices to thousands\n",
    "\n",
    "losses = []\n",
    "for epoch in range(100):\n",
    "    # Forward pass\n",
    "    predictions = model(house_features_norm)\n",
    "    loss = criterion(predictions, house_prices_norm)\n",
    "    \n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Test the trained model\n",
    "print(f\"\\nðŸ” TESTING THE MODEL\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_predictions = model(house_features_norm) * 1000  # Scale back to original prices\n",
    "    \n",
    "print(f\"Predictions vs Actual:\")\n",
    "for i in range(len(house_features)):\n",
    "    actual = house_prices[i].item()\n",
    "    predicted = test_predictions[i].item()\n",
    "    error = abs(actual - predicted)\n",
    "    print(f\"House {i+1}: Predicted ${predicted:,.0f}, Actual ${actual:,.0f}, Error ${error:,.0f}\")\n",
    "\n",
    "# Visualize training progress\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(losses)\n",
    "plt.title('Training Loss Over Time')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "actual_prices = house_prices.numpy().flatten()\n",
    "pred_prices = test_predictions.numpy().flatten()\n",
    "plt.scatter(actual_prices, pred_prices)\n",
    "plt.plot([min(actual_prices), max(actual_prices)], [min(actual_prices), max(actual_prices)], 'r--')\n",
    "plt.xlabel('Actual Price')\n",
    "plt.ylabel('Predicted Price')\n",
    "plt.title('Predictions vs Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Make prediction for new house\n",
    "new_house = torch.tensor([[2000, 3]], dtype=torch.float32)  # 2000 sqft, 3 bedrooms\n",
    "new_house_norm = (new_house - house_features.mean(dim=0)) / house_features.std(dim=0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    new_prediction = model(new_house_norm) * 1000\n",
    "    print(f\"\\nNew house prediction: 2000 sqft, 3 bedrooms â†’ ${new_prediction.item():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cc4b0b",
   "metadata": {},
   "source": [
    "## 3. Classification with Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2881910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification: Predicting categories (not numbers)\n",
    "print(\"ðŸŽ¯ CLASSIFICATION: Customer purchase prediction\")\n",
    "\n",
    "# Generate sample customer data\n",
    "X, y = make_classification(n_samples=1000, n_features=4, n_classes=2, random_state=42)\n",
    "feature_names = ['age', 'income', 'web_visits', 'cart_value']\n",
    "\n",
    "# Convert to tensors\n",
    "X_tensor = torch.FloatTensor(X)\n",
    "y_tensor = torch.LongTensor(y)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training data: {X_train.shape[0]} customers\")\n",
    "print(f\"Test data: {X_test.shape[0]} customers\")\n",
    "print(f\"Features: {feature_names}\")\n",
    "\n",
    "# Classification network\n",
    "class ClassificationNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ClassificationNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(4, 16)\n",
    "        self.layer2 = nn.Linear(16, 8)\n",
    "        self.layer3 = nn.Linear(8, 2)  # 2 classes: buy/not buy\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "\n",
    "# Create and train classification model\n",
    "clf_model = ClassificationNet()\n",
    "criterion = nn.CrossEntropyLoss()  # For classification\n",
    "optimizer = optim.Adam(clf_model.parameters(), lr=0.001)\n",
    "\n",
    "print(f\"\\nðŸ”¥ TRAINING CLASSIFICATION MODEL\")\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "for epoch in range(50):\n",
    "    # Training\n",
    "    clf_model.train()\n",
    "    outputs = clf_model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    accuracy = (predicted == y_train).float().mean()\n",
    "    \n",
    "    train_losses.append(loss.item())\n",
    "    train_accuracies.append(accuracy.item())\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}: Loss = {loss.item():.4f}, Accuracy = {accuracy.item():.3f}\")\n",
    "\n",
    "# Evaluate on test data\n",
    "clf_model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = clf_model(X_test)\n",
    "    _, test_predictions = torch.max(test_outputs.data, 1)\n",
    "    test_accuracy = (test_predictions == y_test).float().mean()\n",
    "    \n",
    "    # Get prediction probabilities\n",
    "    test_probs = torch.softmax(test_outputs, dim=1)\n",
    "\n",
    "print(f\"\\nTest accuracy: {test_accuracy.item():.3f} ({test_accuracy.item()*100:.1f}%)\")\n",
    "\n",
    "# Example predictions\n",
    "print(f\"\\nSample predictions:\")\n",
    "for i in range(5):\n",
    "    features = X_test[i]\n",
    "    actual = y_test[i].item()\n",
    "    predicted = test_predictions[i].item()\n",
    "    confidence = test_probs[i][predicted].item()\n",
    "    \n",
    "    print(f\"Customer {i+1}: Predicted {'Buy' if predicted==1 else 'No Buy'} \"\n",
    "          f\"(Actual: {'Buy' if actual==1 else 'No Buy'}), Confidence: {confidence:.2f}\")\n",
    "\n",
    "# Visualize training progress\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(train_losses)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(train_accuracies)\n",
    "plt.title('Training Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "# Confusion matrix visualization\n",
    "actual_np = y_test.numpy()\n",
    "pred_np = test_predictions.numpy()\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(actual_np, pred_np)\n",
    "\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nðŸ’¡ KEY INSIGHTS:\")\n",
    "print(f\"âœ… Neural networks can solve both regression and classification\")\n",
    "print(f\"âœ… More layers can capture complex patterns\")\n",
    "print(f\"âœ… Dropout prevents overfitting\")\n",
    "print(f\"âœ… CrossEntropyLoss for classification, MSELoss for regression\")\n",
    "print(f\"âœ… Always evaluate on separate test data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdf911e",
   "metadata": {},
   "source": [
    "# Practice Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de90ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Stock price prediction\n",
    "print(\"Exercise 1: Stock Price Prediction\")\n",
    "print(\"Build a neural network to predict stock prices\")\n",
    "\n",
    "# Generate sample stock data\n",
    "days = torch.arange(100, dtype=torch.float32).reshape(-1, 1)\n",
    "prices = 100 + 0.5 * days + 10 * torch.sin(days / 10) + torch.randn(100, 1) * 5\n",
    "\n",
    "# Create sequences (use past 5 days to predict next day)\n",
    "def create_sequences(data, seq_length=5):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return torch.stack(X), torch.stack(y)\n",
    "\n",
    "X_stock, y_stock = create_sequences(prices)\n",
    "print(f\"Stock data shape: {X_stock.shape} -> {y_stock.shape}\")\n",
    "\n",
    "# Your task: Build and train a network for stock prediction\n",
    "# Hint: Use nn.LSTM or multiple nn.Linear layers\n",
    "\n",
    "# Exercise 2: Image classification with MNIST-style data\n",
    "print(f\"\\nExercise 2: Simple Image Classification\")\n",
    "\n",
    "# Create simple 8x8 \"images\" (like digits)\n",
    "def create_simple_images(n_samples=200):\n",
    "    images = torch.randn(n_samples, 64)  # 8x8 = 64 pixels\n",
    "    # Create patterns: positive values = class 1, negative = class 0\n",
    "    labels = (images.mean(dim=1) > 0).long()\n",
    "    return images, labels\n",
    "\n",
    "img_data, img_labels = create_simple_images()\n",
    "print(f\"Image data: {img_data.shape}, Labels: {img_labels.shape}\")\n",
    "\n",
    "# Your task: Build CNN-style network for image classification\n",
    "class ImageNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(64, 32)\n",
    "        self.layer2 = nn.Linear(32, 16)\n",
    "        self.layer3 = nn.Linear(16, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "\n",
    "# Train the image classifier\n",
    "img_model = ImageNet()\n",
    "img_criterion = nn.CrossEntropyLoss()\n",
    "img_optimizer = optim.Adam(img_model.parameters(), lr=0.001)\n",
    "\n",
    "# Split data\n",
    "X_img_train, X_img_test, y_img_train, y_img_test = train_test_split(\n",
    "    img_data, img_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Quick training loop\n",
    "print(\"Training image classifier...\")\n",
    "for epoch in range(30):\n",
    "    outputs = img_model(X_img_train)\n",
    "    loss = img_criterion(outputs, y_img_train)\n",
    "    \n",
    "    img_optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    img_optimizer.step()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        accuracy = (predicted == y_img_train).float().mean()\n",
    "        print(f\"Epoch {epoch}: Loss = {loss.item():.4f}, Accuracy = {accuracy:.3f}\")\n",
    "\n",
    "# Test accuracy\n",
    "with torch.no_grad():\n",
    "    test_outputs = img_model(X_img_test)\n",
    "    _, test_pred = torch.max(test_outputs, 1)\n",
    "    test_acc = (test_pred == y_img_test).float().mean()\n",
    "    print(f\"Test accuracy: {test_acc:.3f}\")\n",
    "\n",
    "# Exercise 3: Experiment with architecture\n",
    "print(f\"\\nExercise 3: Architecture Experiments\")\n",
    "print(\"Try these modifications and see how performance changes:\")\n",
    "\n",
    "# Different architectures to try\n",
    "architectures = {\n",
    "    'Small': [4, 8, 2],\n",
    "    'Medium': [4, 16, 8, 2], \n",
    "    'Large': [4, 32, 16, 8, 2],\n",
    "    'Deep': [4, 16, 16, 16, 16, 2]\n",
    "}\n",
    "\n",
    "def create_network(layers):\n",
    "    modules = []\n",
    "    for i in range(len(layers)-1):\n",
    "        modules.append(nn.Linear(layers[i], layers[i+1]))\n",
    "        if i < len(layers)-2:  # No activation after last layer\n",
    "            modules.append(nn.ReLU())\n",
    "    return nn.Sequential(*modules)\n",
    "\n",
    "print(\"Architecture comparison:\")\n",
    "for name, layers in architectures.items():\n",
    "    model = create_network(layers)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"{name}: {layers} -> {total_params} parameters\")\n",
    "\n",
    "# Exercise 4: Regularization techniques\n",
    "print(f\"\\nExercise 4: Preventing Overfitting\")\n",
    "\n",
    "class RegularizedNet(nn.Module):\n",
    "    def __init__(self, dropout_rate=0.2):\n",
    "        super(RegularizedNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(4, 32)\n",
    "        self.layer2 = nn.Linear(32, 16)\n",
    "        self.layer3 = nn.Linear(16, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.batch_norm = nn.BatchNorm1d(32)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm(self.relu(self.layer1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "\n",
    "print(\"Regularization techniques:\")\n",
    "print(\"âœ… Dropout: Randomly turn off neurons during training\")\n",
    "print(\"âœ… Batch Normalization: Normalize inputs to each layer\")\n",
    "print(\"âœ… Weight Decay: Add penalty for large weights\")\n",
    "print(\"âœ… Early Stopping: Stop training when validation loss increases\")\n",
    "\n",
    "# Exercise 5: Learning rate experiments\n",
    "print(f\"\\nExercise 5: Learning Rate Tuning\")\n",
    "learning_rates = [0.1, 0.01, 0.001, 0.0001]\n",
    "\n",
    "print(\"Try different learning rates:\")\n",
    "for lr in learning_rates:\n",
    "    print(f\"Learning rate {lr}: {'Too high (loss explodes)' if lr > 0.01 else 'Good' if lr >= 0.001 else 'Too low (slow learning)'}\")\n",
    "\n",
    "# Key takeaways\n",
    "print(f\"\\nðŸŽ¯ KEY TAKEAWAYS:\")\n",
    "print(f\"âœ… Start simple, then add complexity\")\n",
    "print(f\"âœ… More data usually beats more complex models\") \n",
    "print(f\"âœ… Regularization prevents overfitting\")\n",
    "print(f\"âœ… Learning rate is crucial for training\")\n",
    "print(f\"âœ… Always validate on separate test data\")\n",
    "print(f\"âœ… PyTorch gives you full control over the training process\")\n",
    "\n",
    "# Next steps\n",
    "print(f\"\\nðŸš€ NEXT STEPS:\")\n",
    "print(f\"1. Try convolutional layers for image data\")\n",
    "print(f\"2. Experiment with LSTM for sequence data\")\n",
    "print(f\"3. Use pre-trained models (transfer learning)\")\n",
    "print(f\"4. Deploy models to production\")\n",
    "print(f\"5. Learn about transformers and attention mechanisms\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d284b3c",
   "metadata": {},
   "source": [
    "# Computer Vision\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this lesson, you will be able to:\n",
    "- Understand how computers process images\n",
    "- Build image classification models\n",
    "- Use convolutional neural networks (CNNs)\n",
    "- Apply pre-trained models to real problems\n",
    "\n",
    "## Core Concepts\n",
    "- **Pixel**: Individual dots that make up an image (like tiny colored squares)\n",
    "- **CNN**: Neural network designed specifically for images\n",
    "- **Feature Map**: Patterns the network learns to recognize (edges, shapes)\n",
    "- **Transfer Learning**: Using pre-trained models for new tasks\n",
    "- **Classification**: Determining what object is in an image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172d692e",
   "metadata": {},
   "source": [
    "## 1. Understanding Images as Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151576f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"üëÅÔ∏è COMPUTER VISION FUNDAMENTALS\")\n",
    "\n",
    "# Understanding images as numbers\n",
    "print(\"üì∏ IMAGES AS DATA:\")\n",
    "\n",
    "# Create a simple 8x8 image (like a tiny digit)\n",
    "simple_image = np.array([\n",
    "    [0, 0, 1, 1, 1, 1, 0, 0],\n",
    "    [0, 1, 1, 0, 0, 1, 1, 0],\n",
    "    [1, 1, 0, 0, 0, 0, 1, 1],\n",
    "    [1, 0, 0, 0, 0, 0, 0, 1],\n",
    "    [1, 0, 0, 0, 0, 0, 0, 1],\n",
    "    [1, 1, 0, 0, 0, 0, 1, 1],\n",
    "    [0, 1, 1, 0, 0, 1, 1, 0],\n",
    "    [0, 0, 1, 1, 1, 1, 0, 0]\n",
    "])\n",
    "\n",
    "print(f\"Image as numbers:\")\n",
    "print(simple_image)\n",
    "print(f\"Shape: {simple_image.shape} (8 rows, 8 columns)\")\n",
    "\n",
    "# Visualize the image\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "ax1.imshow(simple_image, cmap='gray')\n",
    "ax1.set_title('As Image')\n",
    "ax1.axis('off')\n",
    "\n",
    "ax2.imshow(simple_image, cmap='gray')\n",
    "ax2.set_title('With Pixel Values')\n",
    "for i in range(8):\n",
    "    for j in range(8):\n",
    "        ax2.text(j, i, simple_image[i, j], ha='center', va='center', color='red')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Color images have 3 channels (Red, Green, Blue)\n",
    "print(f\"\\nüåà COLOR IMAGES:\")\n",
    "color_pixel = np.array([255, 0, 0])  # Pure red\n",
    "print(f\"Red pixel: R={color_pixel[0]}, G={color_pixel[1]}, B={color_pixel[2]}\")\n",
    "\n",
    "# Create sample colored image (3x3 pixels, 3 colors)\n",
    "color_image = np.random.randint(0, 256, (3, 3, 3))\n",
    "print(f\"Color image shape: {color_image.shape} (height, width, colors)\")\n",
    "\n",
    "# Generate synthetic image dataset for classification\n",
    "print(f\"\\nüéØ CREATING IMAGE DATASET:\")\n",
    "\n",
    "def create_simple_shapes(n_samples=100):\n",
    "    \"\"\"Create simple shape images for classification\"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        # Create 16x16 image\n",
    "        img = np.zeros((16, 16))\n",
    "        \n",
    "        if i % 2 == 0:  # Circle\n",
    "            center = (8, 8)\n",
    "            radius = 4\n",
    "            y, x = np.ogrid[:16, :16]\n",
    "            mask = (x - center[0])**2 + (y - center[1])**2 <= radius**2\n",
    "            img[mask] = 1\n",
    "            labels.append(0)  # Circle = 0\n",
    "        else:  # Square\n",
    "            img[4:12, 4:12] = 1\n",
    "            labels.append(1)  # Square = 1\n",
    "        \n",
    "        images.append(img.flatten())  # Flatten to 1D array\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Create dataset\n",
    "X_images, y_shapes = create_simple_shapes(200)\n",
    "print(f\"Created {len(X_images)} images\")\n",
    "print(f\"Image shape: {X_images[0].shape} pixels\")\n",
    "print(f\"Classes: 0=Circle, 1=Square\")\n",
    "\n",
    "# Visualize sample images\n",
    "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "for i in range(8):\n",
    "    row = i // 4\n",
    "    col = i % 4\n",
    "    \n",
    "    image = X_images[i].reshape(16, 16)\n",
    "    label = y_shapes[i]\n",
    "    shape = \"Circle\" if label == 0 else \"Square\"\n",
    "    \n",
    "    axes[row, col].imshow(image, cmap='gray')\n",
    "    axes[row, col].set_title(f'{shape}')\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Images are just arrays of numbers\")\n",
    "print(f\"‚úÖ Grayscale: 2D array (height √ó width)\")\n",
    "print(f\"‚úÖ Color: 3D array (height √ó width √ó channels)\")\n",
    "print(f\"‚úÖ Each pixel value represents brightness (0-255)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69d1867",
   "metadata": {},
   "source": [
    "## 2. Convolutional Neural Networks (CNNs)\n",
    "\n",
    "## 3. Image Classification Project\n",
    "\n",
    "# Practice Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500e7f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Convolutional Neural Network\n",
    "print(\"üß† BUILDING A CNN FOR IMAGE CLASSIFICATION\")\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_tensor = torch.FloatTensor(X_images).reshape(-1, 1, 16, 16)  # (batch, channels, height, width)\n",
    "y_tensor = torch.LongTensor(y_shapes)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training data: {X_train.shape}\")\n",
    "print(f\"Test data: {X_test.shape}\")\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=3, padding=1)  # 1 input channel, 8 output channels\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)  # Reduce size by half\n",
    "        \n",
    "        # Dense layers\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 32)  # After pooling: 16x16 -> 8x8 -> 4x4\n",
    "        self.fc2 = nn.Linear(32, 2)  # 2 classes (circle, square)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Convolutional layers\n",
    "        x = self.pool(self.relu(self.conv1(x)))  # 16x16 -> 8x8\n",
    "        x = self.pool(self.relu(self.conv2(x)))  # 8x8 -> 4x4\n",
    "        \n",
    "        # Flatten for dense layers\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        \n",
    "        # Dense layers\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Create and train model\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(f\"Model architecture: {model}\")\n",
    "\n",
    "# Training loop\n",
    "print(f\"\\nüî• TRAINING CNN:\")\n",
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "for epoch in range(30):\n",
    "    # Forward pass\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    \n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    accuracy = (predicted == y_train).float().mean()\n",
    "    \n",
    "    losses.append(loss.item())\n",
    "    accuracies.append(accuracy.item())\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}: Loss = {loss.item():.4f}, Accuracy = {accuracy:.3f}\")\n",
    "\n",
    "# Test the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test)\n",
    "    _, test_predictions = torch.max(test_outputs.data, 1)\n",
    "    test_accuracy = (test_predictions == y_test).float().mean()\n",
    "\n",
    "print(f\"\\nTest accuracy: {test_accuracy:.3f} ({test_accuracy*100:.1f}%)\")\n",
    "\n",
    "# Visualize results\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "\n",
    "# Training progress\n",
    "axes[0, 0].plot(losses)\n",
    "axes[0, 0].set_title('Training Loss')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "\n",
    "axes[0, 1].plot(accuracies)\n",
    "axes[0, 1].set_title('Training Accuracy')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "\n",
    "# Sample predictions\n",
    "for i in range(4):\n",
    "    row = (i // 2) + (1 if i >= 2 else 0)\n",
    "    col = (i % 2) + (2 if i < 2 else 0)\n",
    "    if col > 2: continue\n",
    "    \n",
    "    image = X_test[i].squeeze().numpy()\n",
    "    actual = y_test[i].item()\n",
    "    predicted = test_predictions[i].item()\n",
    "    \n",
    "    actual_label = \"Circle\" if actual == 0 else \"Square\"\n",
    "    pred_label = \"Circle\" if predicted == 0 else \"Square\"\n",
    "    color = 'green' if actual == predicted else 'red'\n",
    "    \n",
    "    axes[row, col].imshow(image, cmap='gray')\n",
    "    axes[row, col].set_title(f'Actual: {actual_label}\\nPredicted: {pred_label}', color=color)\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Practice Exercises\n",
    "print(f\"\\nüìö PRACTICE EXERCISES:\")\n",
    "\n",
    "# Exercise 1: Different shapes\n",
    "print(f\"\\nExercise 1: Add Triangle Shape\")\n",
    "print(\"Modify the dataset to include triangles (3 classes total)\")\n",
    "\n",
    "# Exercise 2: Real images\n",
    "print(f\"\\nExercise 2: Real Image Classification\")\n",
    "print(\"Try the CIFAR-10 dataset with 10 real object classes\")\n",
    "\n",
    "# Exercise 3: Data augmentation\n",
    "print(f\"\\nExercise 3: Data Augmentation\")\n",
    "print(\"Apply rotations, flips, and zoom to increase dataset size\")\n",
    "\n",
    "# Exercise 4: Transfer learning\n",
    "print(f\"\\nExercise 4: Transfer Learning\")\n",
    "print(\"Use a pre-trained model (ResNet, VGG) for better accuracy\")\n",
    "\n",
    "# Exercise 5: Object detection\n",
    "print(f\"\\nExercise 5: Object Detection\")\n",
    "print(\"Find and locate multiple objects in the same image\")\n",
    "\n",
    "# Key insights\n",
    "print(f\"\\nüí° KEY INSIGHTS:\")\n",
    "print(f\"‚úÖ CNNs use convolution to detect features (edges, shapes)\")\n",
    "print(f\"‚úÖ Pooling reduces image size while keeping important info\")\n",
    "print(f\"‚úÖ Multiple layers learn increasingly complex patterns\")\n",
    "print(f\"‚úÖ Data augmentation helps prevent overfitting\")\n",
    "print(f\"‚úÖ Transfer learning saves time and improves accuracy\")\n",
    "\n",
    "print(f\"\\nüöÄ NEXT STEPS:\")\n",
    "print(f\"1. Try larger, real image datasets (CIFAR-10, ImageNet)\")\n",
    "print(f\"2. Use pre-trained models (ResNet, EfficientNet)\")\n",
    "print(f\"3. Learn object detection and segmentation\")\n",
    "print(f\"4. Experiment with GANs for image generation\")\n",
    "print(f\"5. Apply computer vision to real business problems\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf930903",
   "metadata": {},
   "source": [
    "## Real-time Object Detection\n",
    "\n",
    "Build an object detection system that can process images and video streams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca82dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "COMPLETE COMPUTER VISION TUTORIAL\n",
    "=================================\n",
    "\n",
    "This tutorial teaches you computer vision from the ground up.\n",
    "We'll work with images step by step and build real applications.\n",
    "\"\"\"\n",
    "\n",
    "# =============================================================================\n",
    "# PART 1: UNDERSTANDING IMAGES AS DATA\n",
    "# =============================================================================\n",
    "\n",
    "print(\"PART 1: HOW COMPUTERS SEE IMAGES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create a simple image to understand the basics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a simple 8x8 grayscale image (like a tiny digit)\n",
    "simple_image = np.array([\n",
    "    [0, 0, 1, 1, 1, 1, 0, 0],\n",
    "    [0, 1, 1, 1, 1, 1, 1, 0],\n",
    "    [1, 1, 1, 0, 0, 1, 1, 1],\n",
    "    [1, 1, 0, 0, 0, 0, 1, 1],\n",
    "    [1, 1, 0, 0, 0, 0, 1, 1],\n",
    "    [1, 1, 1, 0, 0, 1, 1, 1],\n",
    "    [0, 1, 1, 1, 1, 1, 1, 0],\n",
    "    [0, 0, 1, 1, 1, 1, 0, 0]\n",
    "])\n",
    "\n",
    "print(\"Simple 8x8 image as numbers:\")\n",
    "print(simple_image)\n",
    "print(f\"Image shape: {simple_image.shape}\")\n",
    "print(f\"Data type: {simple_image.dtype}\")\n",
    "print(f\"Min value: {simple_image.min()}, Max value: {simple_image.max()}\")\n",
    "\n",
    "# Visualize the image\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Show as numbers\n",
    "ax1.imshow(simple_image, cmap='gray')\n",
    "ax1.set_title('Image as Pixels')\n",
    "ax1.set_xlabel('Column (x)')\n",
    "ax1.set_ylabel('Row (y)')\n",
    "\n",
    "# Add text annotations showing pixel values\n",
    "for i in range(8):\n",
    "    for j in range(8):\n",
    "        ax1.text(j, i, str(simple_image[i, j]), ha='center', va='center', \n",
    "                color='red' if simple_image[i, j] == 0 else 'white', fontsize=8)\n",
    "\n",
    "# Show as heatmap with values\n",
    "im = ax2.imshow(simple_image, cmap='gray')\n",
    "ax2.set_title('Same Image (Grayscale)')\n",
    "plt.colorbar(im, ax=ax2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Insights:\")\n",
    "print(\"‚Ä¢ Images are just 2D arrays of numbers\")\n",
    "print(\"‚Ä¢ Each number represents pixel intensity (0=black, 1=white)\")\n",
    "print(\"‚Ä¢ Computer vision = finding patterns in these numbers\")\n",
    "\n",
    "# =============================================================================\n",
    "# PART 2: COLOR IMAGES (RGB)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\\nPART 2: COLOR IMAGES - RED, GREEN, BLUE CHANNELS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create a simple 4x4 color image\n",
    "color_image = np.zeros((4, 4, 3), dtype=np.uint8)  # 4x4 pixels, 3 color channels\n",
    "\n",
    "# Make some colored pixels\n",
    "color_image[0, 0] = [255, 0, 0]    # Red pixel\n",
    "color_image[0, 1] = [0, 255, 0]    # Green pixel  \n",
    "color_image[0, 2] = [0, 0, 255]    # Blue pixel\n",
    "color_image[0, 3] = [255, 255, 0]  # Yellow (Red + Green)\n",
    "\n",
    "color_image[1, 0] = [255, 0, 255]  # Magenta (Red + Blue)\n",
    "color_image[1, 1] = [0, 255, 255]  # Cyan (Green + Blue)\n",
    "color_image[1, 2] = [255, 255, 255] # White (All colors)\n",
    "color_image[1, 3] = [128, 128, 128] # Gray\n",
    "\n",
    "print(f\"Color image shape: {color_image.shape}\")\n",
    "print(f\"Red channel (top-left pixel): {color_image[0, 0, 0]}\")\n",
    "print(f\"Green channel (top-left pixel): {color_image[0, 0, 1]}\")\n",
    "print(f\"Blue channel (top-left pixel): {color_image[0, 0, 2]}\")\n",
    "\n",
    "# Visualize color channels\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "# Original color image\n",
    "axes[0, 0].imshow(color_image)\n",
    "axes[0, 0].set_title('Original Color Image')\n",
    "\n",
    "# Red channel only\n",
    "red_channel = color_image.copy()\n",
    "red_channel[:, :, [1, 2]] = 0  # Zero out green and blue\n",
    "axes[0, 1].imshow(red_channel)\n",
    "axes[0, 1].set_title('Red Channel Only')\n",
    "\n",
    "# Green channel only\n",
    "green_channel = color_image.copy()\n",
    "green_channel[:, :, [0, 2]] = 0  # Zero out red and blue\n",
    "axes[1, 0].imshow(green_channel)\n",
    "axes[1, 0].set_title('Green Channel Only')\n",
    "\n",
    "# Blue channel only\n",
    "blue_channel = color_image.copy()\n",
    "blue_channel[:, :, [0, 1]] = 0  # Zero out red and green\n",
    "axes[1, 1].imshow(blue_channel)\n",
    "axes[1, 1].set_title('Blue Channel Only')\n",
    "\n",
    "for ax in axes.flat:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# PART 3: IMAGE OPERATIONS AND FILTERS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\\nPART 3: IMAGE FILTERS - DETECTING FEATURES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create a larger test image with patterns\n",
    "test_image = np.zeros((12, 12))\n",
    "\n",
    "# Add vertical lines\n",
    "test_image[:, 2] = 1\n",
    "test_image[:, 5] = 1\n",
    "test_image[:, 8] = 1\n",
    "\n",
    "# Add horizontal lines\n",
    "test_image[3, :] = 1\n",
    "test_image[7, :] = 1\n",
    "\n",
    "print(\"Test image with vertical and horizontal lines:\")\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(test_image, cmap='gray')\n",
    "plt.title('Test Image with Lines')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# Define filters (kernels) for edge detection\n",
    "def apply_filter(image, kernel):\n",
    "    \"\"\"Apply a filter/kernel to an image\"\"\"\n",
    "    kernel_size = kernel.shape[0]\n",
    "    pad = kernel_size // 2\n",
    "    \n",
    "    # Add padding to handle edges\n",
    "    padded_image = np.pad(image, pad, mode='constant', constant_values=0)\n",
    "    filtered_image = np.zeros_like(image)\n",
    "    \n",
    "    # Apply filter to each position\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            # Extract region under kernel\n",
    "            region = padded_image[i:i+kernel_size, j:j+kernel_size]\n",
    "            # Apply kernel (element-wise multiply and sum)\n",
    "            filtered_image[i, j] = np.sum(region * kernel)\n",
    "    \n",
    "    return filtered_image\n",
    "\n",
    "# Edge detection kernels\n",
    "vertical_edge_kernel = np.array([\n",
    "    [-1, 0, 1],\n",
    "    [-1, 0, 1],\n",
    "    [-1, 0, 1]\n",
    "])\n",
    "\n",
    "horizontal_edge_kernel = np.array([\n",
    "    [-1, -1, -1],\n",
    "    [ 0,  0,  0],\n",
    "    [ 1,  1,  1]\n",
    "])\n",
    "\n",
    "# Apply filters\n",
    "vertical_edges = apply_filter(test_image, vertical_edge_kernel)\n",
    "horizontal_edges = apply_filter(test_image, horizontal_edge_kernel)\n",
    "\n",
    "# Visualize results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "axes[0, 0].imshow(test_image, cmap='gray')\n",
    "axes[0, 0].set_title('Original Image')\n",
    "\n",
    "axes[0, 1].imshow(vertical_edges, cmap='gray')\n",
    "axes[0, 1].set_title('Vertical Edge Detection')\n",
    "\n",
    "axes[1, 0].imshow(horizontal_edges, cmap='gray')  \n",
    "axes[1, 0].set_title('Horizontal Edge Detection')\n",
    "\n",
    "# Combined edges\n",
    "combined_edges = np.sqrt(vertical_edges**2 + horizontal_edges**2)\n",
    "axes[1, 1].imshow(combined_edges, cmap='gray')\n",
    "axes[1, 1].set_title('Combined Edge Detection')\n",
    "\n",
    "for ax in axes.flat:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Filter/Kernel Explanation:\")\n",
    "print(\"‚Ä¢ Filters are small matrices that slide over the image\")\n",
    "print(\"‚Ä¢ They detect specific features (edges, corners, textures)\")\n",
    "print(\"‚Ä¢ Convolutional Neural Networks learn these filters automatically\")\n",
    "\n",
    "# =============================================================================\n",
    "# PART 4: BUILDING A SIMPLE CONVOLUTIONAL NEURAL NETWORK\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\\nPART 4: CONVOLUTIONAL NEURAL NETWORK (CNN)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create a simple CNN for image classification\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        # Convolutional layers (feature extractors)\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)  # Input: 1 channel, Output: 16\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1) # Input: 16, Output: 32\n",
    "        \n",
    "        # Pooling layer (reduces size)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 128)  # 32 channels * 7x7 size = 1568\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        \n",
    "        # Activation and dropout\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Convolutional layers with pooling\n",
    "        x = self.pool(self.relu(self.conv1(x)))  # 28x28 ‚Üí 14x14\n",
    "        x = self.pool(self.relu(self.conv2(x)))  # 14x14 ‚Üí 7x7\n",
    "        \n",
    "        # Flatten for fully connected layers\n",
    "        x = x.view(x.size(0), -1)  # Reshape to (batch_size, features)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Create and test the CNN\n",
    "cnn = SimpleCNN(num_classes=10)\n",
    "print(\"CNN Architecture:\")\n",
    "print(cnn)\n",
    "\n",
    "# Test with fake image data (like MNIST: 28x28 grayscale images)\n",
    "batch_size = 4\n",
    "fake_images = torch.randn(batch_size, 1, 28, 28)  # 4 images, 1 channel, 28x28\n",
    "\n",
    "print(f\"\\nInput shape: {fake_images.shape}\")\n",
    "\n",
    "# Forward pass through the network\n",
    "cnn.eval()\n",
    "with torch.no_grad():\n",
    "    output = cnn(fake_images)\n",
    "\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Output (raw scores): {output[0]}\")  # First image's scores\n",
    "\n",
    "# Convert to probabilities\n",
    "probabilities = F.softmax(output, dim=1)\n",
    "predicted_classes = torch.argmax(probabilities, dim=1)\n",
    "\n",
    "print(f\"Probabilities for first image: {probabilities[0]}\")\n",
    "print(f\"Predicted class for first image: {predicted_classes[0].item()}\")\n",
    "\n",
    "# =============================================================================\n",
    "# PART 5: UNDERSTANDING CONVOLUTION STEP BY STEP\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\\nPART 5: UNDERSTANDING CONVOLUTION OPERATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def visualize_convolution(image, kernel, title=\"Convolution\"):\n",
    "    \"\"\"Visualize how convolution works step by step\"\"\"\n",
    "    \n",
    "    # Apply convolution\n",
    "    result = apply_filter(image, kernel)\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    # Original image\n",
    "    axes[0].imshow(image, cmap='gray')\n",
    "    axes[0].set_title('Input Image')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Kernel\n",
    "    im1 = axes[1].imshow(kernel, cmap='RdBu', vmin=-1, vmax=1)\n",
    "    axes[1].set_title('Filter/Kernel')\n",
    "    plt.colorbar(im1, ax=axes[1])\n",
    "    \n",
    "    # Add values to kernel visualization\n",
    "    for i in range(kernel.shape[0]):\n",
    "        for j in range(kernel.shape[1]):\n",
    "            axes[1].text(j, i, f'{kernel[i,j]:.1f}', ha='center', va='center')\n",
    "    \n",
    "    # Result\n",
    "    im2 = axes[2].imshow(result, cmap='gray')\n",
    "    axes[2].set_title(f'Output: {title}')\n",
    "    plt.colorbar(im2, ax=axes[2])\n",
    "    \n",
    "    for ax in axes:\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test different filters\n",
    "filters = {\n",
    "    'Vertical Edges': np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]]),\n",
    "    'Horizontal Edges': np.array([[-1, -1, -1], [0, 0, 0], [1, 1, 1]]),\n",
    "    'Blur': np.array([[1, 1, 1], [1, 1, 1], [1, 1, 1]]) / 9,\n",
    "    'Sharpen': np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
    "}\n",
    "\n",
    "# Create a more interesting test image\n",
    "interesting_image = np.zeros((16, 16))\n",
    "interesting_image[3:6, 2:14] = 1    # Horizontal bar\n",
    "interesting_image[2:14, 8:11] = 1   # Vertical bar\n",
    "interesting_image[10:13, 3:7] = 1   # Small rectangle\n",
    "\n",
    "print(\"Testing different filters on the same image:\")\n",
    "for filter_name, kernel in filters.items():\n",
    "    result = visualize_convolution(interesting_image, kernel, filter_name)\n",
    "\n",
    "# =============================================================================\n",
    "# PART 6: FEATURE MAPS AND WHAT CNNs LEARN\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\\nPART 6: WHAT CNNs LEARN - FEATURE MAPS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Simulate what different layers of a CNN might detect\n",
    "def create_feature_examples():\n",
    "    \"\"\"Create examples of features that CNN layers typically learn\"\"\"\n",
    "    \n",
    "    # Layer 1: Simple features (edges, corners)\n",
    "    edge_detector = np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]])\n",
    "    corner_detector = np.array([[-1, -1, 0], [-1, 0, 1], [0, 1, 1]])\n",
    "    \n",
    "    # Layer 2: More complex patterns\n",
    "    # (In real CNNs, these would be learned, not hand-crafted)\n",
    "    \n",
    "    # Create test patterns\n",
    "    test_patterns = {\n",
    "        'Vertical Line': np.zeros((8, 8)),\n",
    "        'Corner': np.zeros((8, 8)),\n",
    "        'Cross': np.zeros((8, 8)),\n",
    "        'Circle': np.zeros((8, 8))\n",
    "    }\n",
    "    \n",
    "    # Vertical line\n",
    "    test_patterns['Vertical Line'][:, 4] = 1\n",
    "    \n",
    "    # Corner\n",
    "    test_patterns['Corner'][2:6, 2] = 1\n",
    "    test_patterns['Corner'][5, 2:6] = 1\n",
    "    \n",
    "    # Cross\n",
    "    test_patterns['Cross'][:, 4] = 1\n",
    "    test_patterns['Cross'][4, :] = 1\n",
    "    \n",
    "    # Circle (approximate)\n",
    "    center = 4\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            distance = np.sqrt((i - center)**2 + (j - center)**2)\n",
    "            if 2 <= distance <= 3:\n",
    "                test_patterns['Circle'][i, j] = 1\n",
    "    \n",
    "    return test_patterns\n",
    "\n",
    "test_patterns = create_feature_examples()\n",
    "\n",
    "# Visualize what different \"neurons\" detect\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "for idx, (pattern_name, pattern) in enumerate(test_patterns.items()):\n",
    "    row = idx // 2\n",
    "    col = (idx % 2) * 2\n",
    "    \n",
    "    # Show original pattern\n",
    "    axes[row, col].imshow(pattern, cmap='gray')\n",
    "    axes[row, col].set_title(f'{pattern_name}')\n",
    "    \n",
    "    # Show edge detection response\n",
    "    edge_response = apply_filter(pattern, edge_detector)\n",
    "    axes[row, col + 1].imshow(edge_response, cmap='RdBu')\n",
    "    axes[row, col + 1].set_title(f'{pattern_name} - Edge Response')\n",
    "\n",
    "for ax in axes.flat:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"CNN Feature Hierarchy:\")\n",
    "print(\"‚Ä¢ Layer 1: Detects simple features (edges, corners)\")\n",
    "print(\"‚Ä¢ Layer 2: Combines simple features into patterns (shapes)\")\n",
    "print(\"‚Ä¢ Layer 3: Combines patterns into parts (eyes, wheels)\")\n",
    "print(\"‚Ä¢ Layer 4: Combines parts into objects (faces, cars)\")\n",
    "\n",
    "# =============================================================================\n",
    "# PART 7: TRANSFER LEARNING - USING PRE-TRAINED MODELS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\\nPART 7: TRANSFER LEARNING CONCEPT\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Transfer learning: use models trained on large datasets for your task\n",
    "print(\"Transfer Learning Process:\")\n",
    "print(\"1. Start with pre-trained model (trained on millions of images)\")\n",
    "print(\"2. Remove the final classification layer\")\n",
    "print(\"3. Add your own classification layer for your specific task\")\n",
    "print(\"4. Fine-tune on your data\")\n",
    "\n",
    "# Simulate transfer learning architecture\n",
    "class TransferLearningModel(nn.Module):\n",
    "    def __init__(self, num_classes_new_task=5):\n",
    "        super(TransferLearningModel, self).__init__()\n",
    "        \n",
    "        # Pre-trained feature extractor (frozen)\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "        \n",
    "        # New classifier for your task\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, num_classes_new_task)\n",
    "        )\n",
    "        \n",
    "        # Freeze feature extractor (don't train these layers)\n",
    "        for param in self.feature_extractor.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "    def forward(self, x):\n",
    "        # Extract features using pre-trained layers\n",
    "        features = self.feature_extractor(x)\n",
    "        # Classify using new layers\n",
    "        output = self.classifier(features)\n",
    "        return output\n",
    "\n",
    "# Create transfer learning model\n",
    "transfer_model = TransferLearningModel(num_classes_new_task=5)\n",
    "\n",
    "# Count trainable vs frozen parameters\n",
    "total_params = sum(p.numel() for p in transfer_model.parameters())\n",
    "trainable_params = sum(p.numel() for p in transfer_model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nTransfer Learning Model:\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Frozen parameters: {total_params - trainable_params:,}\")\n",
    "print(f\"Training efficiency: Only {trainable_params/total_params:.1%} of parameters need training!\")\n",
    "\n",
    "# Test with sample data\n",
    "sample_rgb_images = torch.randn(2, 3, 32, 32)  # 2 RGB images, 32x32\n",
    "output = transfer_model(sample_rgb_images)\n",
    "print(f\"Input shape: {sample_rgb_images.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "\n",
    "# =============================================================================\n",
    "# PART 8: OBJECT DETECTION CONCEPT\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\\nPART 8: OBJECT DETECTION - FINDING OBJECTS IN IMAGES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Object detection = Classification + Localization\n",
    "print(\"Object Detection Tasks:\")\n",
    "print(\"1. Classification: What objects are in the image?\")\n",
    "print(\"2. Localization: Where are these objects located?\")\n",
    "print(\"3. Output: Bounding boxes + class labels\")\n",
    "\n",
    "# Simulate object detection on a simple image\n",
    "def simulate_object_detection():\n",
    "    \"\"\"Simulate object detection results\"\"\"\n",
    "    \n",
    "    # Create a simple scene\n",
    "    scene = np.zeros((20, 20))\n",
    "    \n",
    "    # Add objects\n",
    "    scene[5:8, 5:8] = 0.7    # Object 1 (car)\n",
    "    scene[12:15, 10:13] = 0.9  # Object 2 (person)\n",
    "    scene[2:4, 15:17] = 0.5   # Object 3 (bike)\n",
    "    \n",
    "    # Simulate detection results\n",
    "    detections = [\n",
    "        {'class': 'car', 'confidence': 0.95, 'bbox': [5, 5, 3, 3]},\n",
    "        {'class': 'person', 'confidence': 0.87, 'bbox': [12, 10, 3, 3]},\n",
    "        {'class': 'bike', 'confidence': 0.72, 'bbox': [2, 15, 2, 2]}\n",
    "    ]\n",
    "    \n",
    "    # Visualize\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(scene, cmap='gray')\n",
    "    plt.title('Input Image')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(scene, cmap='gray')\n",
    "    \n",
    "    # Draw bounding boxes\n",
    "    colors = ['red', 'blue', 'green']\n",
    "    for i, detection in enumerate(detections):\n",
    "        x, y, w, h = detection['bbox']\n",
    "        confidence = detection['confidence']\n",
    "        class_name = detection['class']\n",
    "        \n",
    "        # Draw rectangle\n",
    "        rect = plt.Rectangle((x-0.5, y-0.5), w, h, linewidth=2, \n",
    "                           edgecolor=colors[i], facecolor='none')\n",
    "        plt.gca().add_patch(rect)\n",
    "        \n",
    "        # Add label\n",
    "        plt.text(x, y-1, f\"{class_name} {confidence:.2f}\", \n",
    "                color=colors[i], fontweight='bold', fontsize=8)\n",
    "    \n",
    "    plt.title('Object Detection Results')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return detections\n",
    "\n",
    "detections = simulate_object_detection()\n",
    "\n",
    "print(\"Detection Results:\")\n",
    "for detection in detections:\n",
    "    print(f\"‚Ä¢ {detection['class']}: {detection['confidence']:.2%} confidence at {detection['bbox']}\")\n",
    "\n",
    "# =============================================================================\n",
    "# SUMMARY AND NEXT STEPS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\\nSUMMARY: COMPUTER VISION CONCEPTS MASTERED\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "‚úÖ Fundamental Concepts:\n",
    "   ‚Ä¢ Images as numerical data (pixels, channels)\n",
    "   ‚Ä¢ Color spaces (RGB) and grayscale conversion\n",
    "   ‚Ä¢ Image filtering and feature detection\n",
    "   ‚Ä¢ Convolution operation and kernels\n",
    "   ‚Ä¢ Feature maps and hierarchical learning\n",
    "\n",
    "‚úÖ Neural Network Architectures:\n",
    "   ‚Ä¢ Convolutional Neural Networks (CNNs)\n",
    "   ‚Ä¢ Pooling layers and dimensionality reduction\n",
    "   ‚Ä¢ Transfer learning and pre-trained models\n",
    "   ‚Ä¢ Feature extraction vs fine-tuning\n",
    "\n",
    "‚úÖ Practical Applications:\n",
    "   ‚Ä¢ Image classification (categorizing images)\n",
    "   ‚Ä¢ Object detection (finding and locating objects)\n",
    "   ‚Ä¢ Feature detection (edges, corners, textures)\n",
    "   ‚Ä¢ Transfer learning for custom tasks\n",
    "\n",
    "‚úÖ Technical Skills:\n",
    "   ‚Ä¢ Building CNNs with PyTorch\n",
    "   ‚Ä¢ Applying image filters and transformations\n",
    "   ‚Ä¢ Understanding feature hierarchies\n",
    "   ‚Ä¢ Implementing transfer learning\n",
    "\n",
    "üéØ Next Steps:\n",
    "   ‚Ä¢ Work with real datasets (MNIST, CIFAR-10, ImageNet)\n",
    "   ‚Ä¢ Explore advanced architectures (ResNet, EfficientNet, YOLO)\n",
    "   ‚Ä¢ Learn about data augmentation techniques\n",
    "   ‚Ä¢ Build end-to-end computer vision applications\n",
    "\"\"\")\n",
    "\n",
    "print(\"üéâ Congratulations! You now understand how computers see and interpret images!\")\n",
    "print(\"You're ready to build real computer vision applications!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

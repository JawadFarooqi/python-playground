{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5e657bc",
   "metadata": {},
   "source": [
    "# AI Applications in Production\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this lesson, you will be able to:\n",
    "- Build and deploy complete AI systems\n",
    "- Implement MLOps practices for production\n",
    "- Create real-world AI applications\n",
    "- Monitor and maintain AI systems in production\n",
    "\n",
    "## Core Concepts\n",
    "- **MLOps**: Managing machine learning models in production\n",
    "- **Model Registry**: Version control for AI models\n",
    "- **Monitoring**: Tracking model performance over time\n",
    "- **A/B Testing**: Comparing different models in production\n",
    "- **Deployment**: Making AI models available to users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f46e61e",
   "metadata": {},
   "source": [
    "## 1. Building AI-Powered Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8208bd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import json\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"üöÄ AI APPLICATIONS IN PRODUCTION\")\n",
    "\n",
    "# Simulate a complete AI application pipeline\n",
    "print(\"üèóÔ∏è BUILDING END-TO-END AI SYSTEM\")\n",
    "\n",
    "# 1. Data Collection and Preprocessing\n",
    "print(\"\\n1. DATA PIPELINE:\")\n",
    "\n",
    "def collect_user_data():\n",
    "    \"\"\"Simulate collecting user interaction data\"\"\"\n",
    "    np.random.seed(42)\n",
    "    data = {\n",
    "        'user_id': range(1000, 1100),\n",
    "        'age': np.random.randint(18, 65, 100),\n",
    "        'income': np.random.normal(50000, 15000, 100),\n",
    "        'clicks': np.random.poisson(5, 100),\n",
    "        'time_on_site': np.random.exponential(10, 100),\n",
    "        'purchases': np.random.binomial(1, 0.3, 100)\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "user_data = collect_user_data()\n",
    "print(f\"Collected data: {user_data.shape[0]} users, {user_data.shape[1]} features\")\n",
    "print(user_data.head())\n",
    "\n",
    "# 2. Model Training and Validation\n",
    "print(f\"\\n2. MODEL DEVELOPMENT:\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Prepare features\n",
    "features = ['age', 'income', 'clicks', 'time_on_site']\n",
    "X = user_data[features]\n",
    "y = user_data['purchases']\n",
    "\n",
    "# Train model with validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Validate model\n",
    "predictions = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "precision = precision_score(y_test, predictions)\n",
    "recall = recall_score(y_test, predictions)\n",
    "\n",
    "print(f\"Model Performance:\")\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall: {recall:.3f}\")\n",
    "\n",
    "# Cross-validation for robustness\n",
    "cv_scores = cross_val_score(model, X, y, cv=5)\n",
    "print(f\"Cross-validation accuracy: {cv_scores.mean():.3f} ¬± {cv_scores.std():.3f}\")\n",
    "\n",
    "# 3. Model Deployment Simulation\n",
    "print(f\"\\n3. MODEL DEPLOYMENT:\")\n",
    "\n",
    "# Save model for production\n",
    "model_filename = 'purchase_prediction_model.pkl'\n",
    "with open(model_filename, 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(f\"‚úÖ Model saved as {model_filename}\")\n",
    "\n",
    "# Create API-like prediction function\n",
    "def predict_purchase_probability(age, income, clicks, time_on_site):\n",
    "    \"\"\"Production prediction function\"\"\"\n",
    "    # Load model (in production, this would be done once at startup)\n",
    "    with open(model_filename, 'rb') as f:\n",
    "        loaded_model = pickle.load(f)\n",
    "    \n",
    "    # Make prediction\n",
    "    features = np.array([[age, income, clicks, time_on_site]])\n",
    "    probability = loaded_model.predict_proba(features)[0][1]\n",
    "    prediction = loaded_model.predict(features)[0]\n",
    "    \n",
    "    return {\n",
    "        'will_purchase': bool(prediction),\n",
    "        'probability': float(probability),\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "# Test the API function\n",
    "test_user = predict_purchase_probability(age=35, income=60000, clicks=8, time_on_site=15)\n",
    "print(f\"Test prediction: {test_user}\")\n",
    "\n",
    "# 4. Real-time monitoring\n",
    "print(f\"\\n4. MONITORING AND MAINTENANCE:\")\n",
    "\n",
    "def monitor_model_performance(new_data, model, threshold=0.05):\n",
    "    \"\"\"Monitor for model drift\"\"\"\n",
    "    current_accuracy = accuracy_score(new_data['actual'], new_data['predicted'])\n",
    "    \n",
    "    if current_accuracy < threshold:\n",
    "        return {\"status\": \"ALERT\", \"message\": \"Model performance degraded\", \"accuracy\": current_accuracy}\n",
    "    else:\n",
    "        return {\"status\": \"OK\", \"message\": \"Model performing well\", \"accuracy\": current_accuracy}\n",
    "\n",
    "# Simulate monitoring\n",
    "monitoring_data = {\n",
    "    'actual': np.random.binomial(1, 0.3, 50),\n",
    "    'predicted': np.random.binomial(1, 0.3, 50)\n",
    "}\n",
    "\n",
    "monitor_result = monitor_model_performance(monitoring_data, model, threshold=0.7)\n",
    "print(f\"Monitoring result: {monitor_result}\")\n",
    "\n",
    "# 5. A/B Testing Framework\n",
    "print(f\"\\n5. A/B TESTING:\")\n",
    "\n",
    "def ab_test_models(model_a, model_b, test_data, metric='accuracy'):\n",
    "    \"\"\"Compare two models using A/B testing\"\"\"\n",
    "    predictions_a = model_a.predict(test_data[features])\n",
    "    predictions_b = model_b.predict(test_data[features])\n",
    "    \n",
    "    if metric == 'accuracy':\n",
    "        score_a = accuracy_score(test_data['purchases'], predictions_a)\n",
    "        score_b = accuracy_score(test_data['purchases'], predictions_b)\n",
    "    \n",
    "    winner = 'Model A' if score_a > score_b else 'Model B'\n",
    "    \n",
    "    return {\n",
    "        'model_a_score': score_a,\n",
    "        'model_b_score': score_b,\n",
    "        'winner': winner,\n",
    "        'improvement': abs(score_a - score_b)\n",
    "    }\n",
    "\n",
    "# Compare with a simpler model\n",
    "simple_model = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "simple_model.fit(X_train, y_train)\n",
    "\n",
    "ab_results = ab_test_models(model, simple_model, user_data.iloc[:50])\n",
    "print(f\"A/B Test Results: {ab_results}\")\n",
    "\n",
    "print(f\"\\n‚úÖ PRODUCTION AI SYSTEM COMPONENTS:\")\n",
    "print(f\"‚Ä¢ Data pipeline for continuous learning\")\n",
    "print(f\"‚Ä¢ Model validation and testing\")\n",
    "print(f\"‚Ä¢ Deployment with API interface\")\n",
    "print(f\"‚Ä¢ Real-time monitoring and alerts\")\n",
    "print(f\"‚Ä¢ A/B testing for model improvements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455d967d",
   "metadata": {},
   "source": [
    "## 2. MLOps and Model Management\n",
    "\n",
    "## 3. Real-World AI Projects\n",
    "\n",
    "# Practice Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faf22fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLOps: Managing AI Models in Production\n",
    "print(\"‚öôÔ∏è MLOPS: MANAGING AI IN PRODUCTION\")\n",
    "\n",
    "# Version control for models\n",
    "print(\"\\nüìÅ MODEL VERSIONING:\")\n",
    "\n",
    "class ModelRegistry:\n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "        self.metadata = {}\n",
    "    \n",
    "    def register_model(self, name, version, model, metrics):\n",
    "        key = f\"{name}_v{version}\"\n",
    "        self.models[key] = model\n",
    "        self.metadata[key] = {\n",
    "            'version': version,\n",
    "            'metrics': metrics,\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'status': 'registered'\n",
    "        }\n",
    "        print(f\"Registered {key} with accuracy: {metrics.get('accuracy', 'N/A')}\")\n",
    "    \n",
    "    def get_best_model(self, name, metric='accuracy'):\n",
    "        versions = [k for k in self.models.keys() if k.startswith(name)]\n",
    "        if not versions:\n",
    "            return None\n",
    "        \n",
    "        best = max(versions, key=lambda v: self.metadata[v]['metrics'].get(metric, 0))\n",
    "        return self.models[best], self.metadata[best]\n",
    "    \n",
    "    def promote_to_production(self, name, version):\n",
    "        key = f\"{name}_v{version}\"\n",
    "        if key in self.models:\n",
    "            self.metadata[key]['status'] = 'production'\n",
    "            print(f\"Promoted {key} to production\")\n",
    "\n",
    "# Use model registry\n",
    "registry = ModelRegistry()\n",
    "registry.register_model('purchase_predictor', '1.0', model, {'accuracy': accuracy, 'precision': precision})\n",
    "\n",
    "# Automated model retraining\n",
    "print(f\"\\nüîÑ AUTOMATED RETRAINING:\")\n",
    "\n",
    "def check_for_retraining(performance_threshold=0.8, data_drift_threshold=0.1):\n",
    "    \"\"\"Check if model needs retraining\"\"\"\n",
    "    current_performance = 0.75  # Simulated current performance\n",
    "    data_drift_score = 0.15     # Simulated drift measurement\n",
    "    \n",
    "    needs_retraining = (\n",
    "        current_performance < performance_threshold or \n",
    "        data_drift_score > data_drift_threshold\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'needs_retraining': needs_retraining,\n",
    "        'current_performance': current_performance,\n",
    "        'data_drift': data_drift_score,\n",
    "        'thresholds': {\n",
    "            'performance': performance_threshold,\n",
    "            'drift': data_drift_threshold\n",
    "        }\n",
    "    }\n",
    "\n",
    "retraining_check = check_for_retraining()\n",
    "print(f\"Retraining check: {retraining_check}\")\n",
    "\n",
    "# Real-World AI Project Examples\n",
    "print(f\"\\nüåç REAL-WORLD AI PROJECT SCENARIOS:\")\n",
    "\n",
    "# Project 1: Customer Churn Prevention\n",
    "print(f\"\\n1. CUSTOMER CHURN PREVENTION:\")\n",
    "def churn_prevention_system():\n",
    "    \"\"\"Complete churn prevention pipeline\"\"\"\n",
    "    \n",
    "    # Simulate customer behavior data\n",
    "    customers = pd.DataFrame({\n",
    "        'customer_id': range(1, 501),\n",
    "        'months_active': np.random.randint(1, 36, 500),\n",
    "        'support_tickets': np.random.poisson(2, 500),\n",
    "        'monthly_spending': np.random.normal(150, 50, 500),\n",
    "        'login_frequency': np.random.poisson(10, 500)\n",
    "    })\n",
    "    \n",
    "    # Create churn labels (customers with low engagement)\n",
    "    customers['will_churn'] = (\n",
    "        (customers['login_frequency'] < 5) | \n",
    "        (customers['support_tickets'] > 5) |\n",
    "        (customers['monthly_spending'] < 100)\n",
    "    ).astype(int)\n",
    "    \n",
    "    # Train churn model\n",
    "    features = ['months_active', 'support_tickets', 'monthly_spending', 'login_frequency']\n",
    "    X = customers[features]\n",
    "    y = customers['will_churn']\n",
    "    \n",
    "    churn_model = RandomForestClassifier(n_estimators=30, random_state=42)\n",
    "    churn_model.fit(X, y)\n",
    "    \n",
    "    # Identify high-risk customers\n",
    "    probabilities = churn_model.predict_proba(X)[:, 1]\n",
    "    high_risk = customers[probabilities > 0.7]\n",
    "    \n",
    "    return {\n",
    "        'total_customers': len(customers),\n",
    "        'high_risk_customers': len(high_risk),\n",
    "        'potential_revenue_loss': high_risk['monthly_spending'].sum() * 12,\n",
    "        'model_accuracy': churn_model.score(X, y)\n",
    "    }\n",
    "\n",
    "churn_results = churn_prevention_system()\n",
    "print(f\"Churn prevention results: {churn_results}\")\n",
    "\n",
    "# Project 2: Inventory Optimization\n",
    "print(f\"\\n2. INVENTORY OPTIMIZATION:\")\n",
    "def inventory_optimization():\n",
    "    \"\"\"AI-powered inventory management\"\"\"\n",
    "    \n",
    "    # Simulate product sales data\n",
    "    products = pd.DataFrame({\n",
    "        'product_id': range(1, 101),\n",
    "        'avg_daily_sales': np.random.poisson(15, 100),\n",
    "        'seasonality_factor': np.random.uniform(0.8, 1.2, 100),\n",
    "        'supplier_lead_time': np.random.randint(3, 14, 100),\n",
    "        'unit_cost': np.random.uniform(10, 100, 100)\n",
    "    })\n",
    "    \n",
    "    # Calculate optimal stock levels\n",
    "    products['safety_stock'] = products['avg_daily_sales'] * products['supplier_lead_time'] * 1.5\n",
    "    products['reorder_point'] = products['avg_daily_sales'] * products['supplier_lead_time'] + products['safety_stock']\n",
    "    products['optimal_stock'] = products['reorder_point'] * 2\n",
    "    \n",
    "    # Calculate potential savings\n",
    "    current_stock_value = products['unit_cost'].sum() * 100  # Assume 100 units per product\n",
    "    optimal_stock_value = (products['unit_cost'] * products['optimal_stock']).sum()\n",
    "    savings = current_stock_value - optimal_stock_value\n",
    "    \n",
    "    return {\n",
    "        'products_analyzed': len(products),\n",
    "        'current_inventory_value': current_stock_value,\n",
    "        'optimized_inventory_value': optimal_stock_value,\n",
    "        'potential_savings': max(0, savings),\n",
    "        'avg_stock_reduction': (100 - products['optimal_stock'].mean()) / 100\n",
    "    }\n",
    "\n",
    "inventory_results = inventory_optimization()\n",
    "print(f\"Inventory optimization results: {inventory_results}\")\n",
    "\n",
    "# Project 3: Fraud Detection\n",
    "print(f\"\\n3. FRAUD DETECTION SYSTEM:\")\n",
    "def fraud_detection_system():\n",
    "    \"\"\"Real-time fraud detection\"\"\"\n",
    "    \n",
    "    # Simulate transaction data\n",
    "    transactions = pd.DataFrame({\n",
    "        'amount': np.random.lognormal(4, 1, 1000),\n",
    "        'hour_of_day': np.random.randint(0, 24, 1000),\n",
    "        'merchant_risk_score': np.random.uniform(0, 1, 1000),\n",
    "        'user_spending_pattern': np.random.normal(0, 1, 1000),\n",
    "        'location_risk': np.random.uniform(0, 1, 1000)\n",
    "    })\n",
    "    \n",
    "    # Create fraud labels (rare events)\n",
    "    fraud_probability = (\n",
    "        0.1 * (transactions['amount'] > 1000) +\n",
    "        0.05 * (transactions['merchant_risk_score'] > 0.8) +\n",
    "        0.03 * (transactions['location_risk'] > 0.9)\n",
    "    )\n",
    "    \n",
    "    transactions['is_fraud'] = np.random.binomial(1, fraud_probability)\n",
    "    \n",
    "    # Train fraud detection model\n",
    "    features = ['amount', 'hour_of_day', 'merchant_risk_score', 'user_spending_pattern', 'location_risk']\n",
    "    X = transactions[features]\n",
    "    y = transactions['is_fraud']\n",
    "    \n",
    "    fraud_model = RandomForestClassifier(n_estimators=50, random_state=42, class_weight='balanced')\n",
    "    fraud_model.fit(X, y)\n",
    "    \n",
    "    # Evaluate fraud detection\n",
    "    predictions = fraud_model.predict(X)\n",
    "    fraud_detected = np.sum(predictions)\n",
    "    actual_fraud = np.sum(y)\n",
    "    \n",
    "    return {\n",
    "        'total_transactions': len(transactions),\n",
    "        'actual_fraud_cases': actual_fraud,\n",
    "        'detected_fraud_cases': fraud_detected,\n",
    "        'detection_rate': fraud_detected / max(actual_fraud, 1),\n",
    "        'model_precision': precision_score(y, predictions) if fraud_detected > 0 else 0\n",
    "    }\n",
    "\n",
    "fraud_results = fraud_detection_system()\n",
    "print(f\"Fraud detection results: {fraud_results}\")\n",
    "\n",
    "# Practice Exercises\n",
    "print(f\"\\nüìö COMPREHENSIVE PRACTICE EXERCISES:\")\n",
    "\n",
    "# Exercise 1: Build a recommendation system\n",
    "print(f\"\\nExercise 1: Recommendation System\")\n",
    "print(\"Build a system that recommends products based on user behavior\")\n",
    "print(\"- Collaborative filtering (user-based)\")\n",
    "print(\"- Content-based filtering (item features)\")\n",
    "print(\"- Hybrid approach combining both methods\")\n",
    "\n",
    "# Exercise 2: Time series forecasting\n",
    "print(f\"\\nExercise 2: Sales Forecasting\")\n",
    "print(\"Predict future sales using historical data\")\n",
    "print(\"- Handle seasonality and trends\")\n",
    "print(\"- Use ARIMA or neural networks\")\n",
    "print(\"- Evaluate forecast accuracy\")\n",
    "\n",
    "# Exercise 3: Natural language processing\n",
    "print(f\"\\nExercise 3: Customer Service Chatbot\")\n",
    "print(\"Build an AI assistant for customer support\")\n",
    "print(\"- Intent classification\")\n",
    "print(\"- Entity extraction\")\n",
    "print(\"- Response generation\")\n",
    "\n",
    "# Exercise 4: Computer vision application\n",
    "print(f\"\\nExercise 4: Quality Control System\")\n",
    "print(\"Detect defects in manufacturing using images\")\n",
    "print(\"- Image preprocessing\")\n",
    "print(\"- Defect classification\")\n",
    "print(\"- Real-time processing\")\n",
    "\n",
    "# Exercise 5: End-to-end MLOps\n",
    "print(f\"\\nExercise 5: Complete MLOps Pipeline\")\n",
    "print(\"Build a production-ready ML system\")\n",
    "print(\"- Automated data pipelines\")\n",
    "print(\"- Model versioning and deployment\")\n",
    "print(\"- Monitoring and alerting\")\n",
    "print(\"- A/B testing framework\")\n",
    "\n",
    "# Career path guidance\n",
    "print(f\"\\nüéØ CAREER PATHS IN AI:\")\n",
    "print(f\"\\n1. DATA SCIENTIST:\")\n",
    "print(f\"   ‚Ä¢ Build models and analyze data\")\n",
    "print(f\"   ‚Ä¢ Focus on statistics and algorithms\")\n",
    "print(f\"   ‚Ä¢ Skills: Python, SQL, Statistics, ML\")\n",
    "\n",
    "print(f\"\\n2. ML ENGINEER:\")\n",
    "print(f\"   ‚Ä¢ Deploy models to production\")\n",
    "print(f\"   ‚Ä¢ Focus on scalability and reliability\")\n",
    "print(f\"   ‚Ä¢ Skills: Python, Docker, Kubernetes, MLOps\")\n",
    "\n",
    "print(f\"\\n3. AI RESEARCHER:\")\n",
    "print(f\"   ‚Ä¢ Develop new AI techniques\")\n",
    "print(f\"   ‚Ä¢ Focus on innovation and research\")\n",
    "print(f\"   ‚Ä¢ Skills: Deep learning, Mathematics, Research\")\n",
    "\n",
    "print(f\"\\n4. AI PRODUCT MANAGER:\")\n",
    "print(f\"   ‚Ä¢ Guide AI product development\")\n",
    "print(f\"   ‚Ä¢ Focus on business impact\")\n",
    "print(f\"   ‚Ä¢ Skills: Business, AI understanding, Strategy\")\n",
    "\n",
    "# Final project ideas\n",
    "print(f\"\\nüöÄ CAPSTONE PROJECT IDEAS:\")\n",
    "print(f\"1. Personal finance AI advisor\")\n",
    "print(f\"2. Smart home automation system\")\n",
    "print(f\"3. Health monitoring application\")\n",
    "print(f\"4. Educational AI tutor\")\n",
    "print(f\"5. Business process optimization tool\")\n",
    "\n",
    "print(f\"\\nüéâ CONGRATULATIONS!\")\n",
    "print(f\"You've completed the comprehensive AI/ML curriculum!\")\n",
    "print(f\"You now have the skills to:\")\n",
    "print(f\"‚úÖ Build end-to-end ML systems\")\n",
    "print(f\"‚úÖ Deploy models to production\")\n",
    "print(f\"‚úÖ Apply AI to real business problems\")\n",
    "print(f\"‚úÖ Continue learning advanced topics\")\n",
    "print(f\"‚úÖ Start your career in AI/ML\")\n",
    "\n",
    "print(f\"\\nüåü KEEP LEARNING:\")\n",
    "print(f\"‚Ä¢ Practice with real datasets\")\n",
    "print(f\"‚Ä¢ Contribute to open source projects\")\n",
    "print(f\"‚Ä¢ Build a portfolio on GitHub\")\n",
    "print(f\"‚Ä¢ Join AI communities and competitions\")\n",
    "print(f\"‚Ä¢ Stay updated with latest research\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9574cd0a",
   "metadata": {},
   "source": [
    "## Build an AI Assistant\n",
    "\n",
    "Create a sophisticated AI assistant using RAG and modern LLM techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9957814c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "COMPLETE MODERN AI APPLICATIONS TUTORIAL\n",
    "=======================================\n",
    "\n",
    "This tutorial teaches you to build modern AI systems like ChatGPT, \n",
    "document Q&A systems, and AI agents.\n",
    "\"\"\"\n",
    "\n",
    "# =============================================================================\n",
    "# PART 1: UNDERSTANDING LARGE LANGUAGE MODELS (LLMs)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"PART 1: UNDERSTANDING LARGE LANGUAGE MODELS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# LLMs are massive neural networks trained on enormous amounts of text\n",
    "print(\"What are Large Language Models?\")\n",
    "print(\"‚Ä¢ Massive neural networks (100+ billion parameters)\")\n",
    "print(\"‚Ä¢ Trained on internet-scale text data\")\n",
    "print(\"‚Ä¢ Learn to predict the next word in a sequence\")\n",
    "print(\"‚Ä¢ Can understand context and generate human-like text\")\n",
    "\n",
    "print(\"\\nHow LLMs Work (Simplified):\")\n",
    "print(\"1. Input: 'The weather today is'\")\n",
    "print(\"2. Model predicts next word probabilities:\")\n",
    "print(\"   - 'sunny': 30%\")\n",
    "print(\"   - 'rainy': 25%\") \n",
    "print(\"   - 'cloudy': 20%\")\n",
    "print(\"   - 'nice': 15%\")\n",
    "print(\"   - other: 10%\")\n",
    "print(\"3. Select word (often highest probability)\")\n",
    "print(\"4. Repeat with new sequence: 'The weather today is sunny'\")\n",
    "\n",
    "# Simulate a simple language model\n",
    "class SimpleLanguageModel:\n",
    "    \"\"\"Simplified language model for educational purposes\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Simple word transition probabilities\n",
    "        self.transitions = {\n",
    "            'the': {'weather': 0.3, 'cat': 0.2, 'sun': 0.2, 'book': 0.3},\n",
    "            'weather': {'is': 0.7, 'today': 0.3},\n",
    "            'today': {'is': 0.8, 'was': 0.2},\n",
    "            'is': {'sunny': 0.4, 'rainy': 0.3, 'cloudy': 0.2, 'good': 0.1},\n",
    "            'cat': {'is': 0.5, 'sleeps': 0.3, 'runs': 0.2},\n",
    "            'sun': {'is': 0.6, 'shines': 0.4}\n",
    "        }\n",
    "    \n",
    "    def predict_next_word(self, current_word):\n",
    "        \"\"\"Predict next word given current word\"\"\"\n",
    "        if current_word.lower() in self.transitions:\n",
    "            return self.transitions[current_word.lower()]\n",
    "        else:\n",
    "            return {'unknown': 1.0}\n",
    "    \n",
    "    def generate_text(self, start_word, length=5):\n",
    "        \"\"\"Generate text starting from a word\"\"\"\n",
    "        result = [start_word]\n",
    "        current = start_word\n",
    "        \n",
    "        for _ in range(length - 1):\n",
    "            predictions = self.predict_next_word(current)\n",
    "            if predictions:\n",
    "                # Choose word with highest probability\n",
    "                next_word = max(predictions.items(), key=lambda x: x[1])[0]\n",
    "                result.append(next_word)\n",
    "                current = next_word\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "        return ' '.join(result)\n",
    "\n",
    "# Test our simple model\n",
    "simple_model = SimpleLanguageModel()\n",
    "\n",
    "print(\"\\nSimple Language Model Demo:\")\n",
    "start_words = ['the', 'cat', 'weather']\n",
    "for word in start_words:\n",
    "    generated = simple_model.generate_text(word, 5)\n",
    "    predictions = simple_model.predict_next_word(word)\n",
    "    print(f\"Starting with '{word}':\")\n",
    "    print(f\"  Generated: {generated}\")\n",
    "    print(f\"  Next word probabilities: {predictions}\")\n",
    "\n",
    "# =============================================================================\n",
    "# PART 2: PROMPT ENGINEERING - TALKING TO AI\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\\nPART 2: PROMPT ENGINEERING - HOW TO TALK TO AI\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"Prompt engineering is the art of writing effective instructions for AI models.\")\n",
    "\n",
    "# Examples of good vs bad prompts\n",
    "prompt_examples = {\n",
    "    \"Bad Prompts\": [\n",
    "        \"Write something about dogs\",\n",
    "        \"Help me\",\n",
    "        \"What should I do?\"\n",
    "    ],\n",
    "    \"Good Prompts\": [\n",
    "        \"Write a 100-word paragraph about why dogs make good pets, including specific benefits like companionship and security.\",\n",
    "        \"I'm learning Python and getting a 'KeyError' when accessing dictionary keys. Explain what this means and show me how to handle it safely.\",\n",
    "        \"I want to start exercising but have only 30 minutes per day. Create a weekly workout plan for a beginner.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"Prompt Quality Examples:\")\n",
    "print(\"-\" * 40)\n",
    "for category, prompts in prompt_examples.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for i, prompt in enumerate(prompts, 1):\n",
    "        print(f\"  {i}. {prompt}\")\n",
    "\n",
    "# Prompt engineering techniques\n",
    "techniques = {\n",
    "    \"Be Specific\": \"Instead of 'write code', say 'write a Python function that calculates compound interest'\",\n",
    "    \"Provide Context\": \"I'm a beginner in Python. Explain functions with simple examples.\",\n",
    "    \"Use Examples\": \"Format the output like this: Name: John, Age: 25, City: NYC\",\n",
    "    \"Set Constraints\": \"Respond in exactly 3 bullet points, each under 20 words\",\n",
    "    \"Chain of Thought\": \"Think step by step: 1) Analyze the problem 2) Plan the solution 3) Write the code\"\n",
    "}\n",
    "\n",
    "print(f\"\\nPrompt Engineering Techniques:\")\n",
    "print(\"-\" * 40)\n",
    "for technique, example in techniques.items():\n",
    "    print(f\"‚Ä¢ {technique}: {example}\")\n",
    "\n",
    "# =============================================================================\n",
    "# PART 3: RETRIEVAL AUGMENTED GENERATION (RAG) SYSTEMS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\\nPART 3: RAG SYSTEMS - GIVING AI ACCESS TO KNOWLEDGE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"Problem: LLMs have knowledge cutoffs and can't access new information.\")\n",
    "print(\"Solution: RAG = Retrieval Augmented Generation\")\n",
    "print(\"\\nRAG Process:\")\n",
    "print(\"1. User asks a question\")\n",
    "print(\"2. Search relevant documents/information\")\n",
    "print(\"3. Provide found information + question to LLM\")\n",
    "print(\"4. LLM generates answer based on retrieved context\")\n",
    "\n",
    "# Simulate a simple RAG system\n",
    "class SimpleRAGSystem:\n",
    "    \"\"\"Simplified RAG system for educational purposes\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Knowledge base (in practice, this would be much larger)\n",
    "        self.knowledge_base = [\n",
    "            {\n",
    "                \"id\": 1,\n",
    "                \"text\": \"Python is a high-level programming language known for its readability and simplicity. It was created by Guido van Rossum in 1991.\",\n",
    "                \"topic\": \"python_basics\"\n",
    "            },\n",
    "            {\n",
    "                \"id\": 2, \n",
    "                \"text\": \"Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed.\",\n",
    "                \"topic\": \"machine_learning\"\n",
    "            },\n",
    "            {\n",
    "                \"id\": 3,\n",
    "                \"text\": \"Neural networks are computing systems inspired by biological neural networks. They consist of interconnected nodes that process information.\",\n",
    "                \"topic\": \"neural_networks\"\n",
    "            },\n",
    "            {\n",
    "                \"id\": 4,\n",
    "                \"text\": \"Data science involves extracting insights from large amounts of data using statistical methods, programming, and domain expertise.\",\n",
    "                \"topic\": \"data_science\"\n",
    "            }\n",
    "        ]\n",
    "    \n",
    "    def search_knowledge(self, query, top_k=2):\n",
    "        \"\"\"Search for relevant documents (simplified keyword matching)\"\"\"\n",
    "        query_words = set(query.lower().split())\n",
    "        scored_docs = []\n",
    "        \n",
    "        for doc in self.knowledge_base:\n",
    "            doc_words = set(doc[\"text\"].lower().split())\n",
    "            # Simple scoring: count of matching words\n",
    "            score = len(query_words.intersection(doc_words))\n",
    "            scored_docs.append((score, doc))\n",
    "        \n",
    "        # Sort by score and return top_k\n",
    "        scored_docs.sort(key=lambda x: x[0], reverse=True)\n",
    "        return [doc for score, doc in scored_docs[:top_k] if score > 0]\n",
    "    \n",
    "    def generate_answer(self, query, retrieved_docs):\n",
    "        \"\"\"Generate answer using query and retrieved documents\"\"\"\n",
    "        if not retrieved_docs:\n",
    "            return \"I don't have information about that topic in my knowledge base.\"\n",
    "        \n",
    "        # Combine retrieved information\n",
    "        context = \" \".join([doc[\"text\"] for doc in retrieved_docs])\n",
    "        \n",
    "        # Simulate LLM response (in practice, this would call a real LLM)\n",
    "        answer = f\"Based on the available information: {context}\\n\\nTo answer your question '{query}': \"\n",
    "        \n",
    "        # Simple rule-based response generation\n",
    "        if \"what is\" in query.lower() and \"python\" in query.lower():\n",
    "            answer += \"Python is a high-level programming language known for its readability and simplicity, created by Guido van Rossum in 1991.\"\n",
    "        elif \"machine learning\" in query.lower():\n",
    "            answer += \"Machine learning is a subset of AI that enables computers to learn from experience without explicit programming.\"\n",
    "        else:\n",
    "            answer += \"The retrieved documents contain relevant information about your query.\"\n",
    "            \n",
    "        return answer\n",
    "    \n",
    "    def ask_question(self, query):\n",
    "        \"\"\"Complete RAG pipeline\"\"\"\n",
    "        print(f\"Query: {query}\")\n",
    "        \n",
    "        # Step 1: Retrieve relevant documents\n",
    "        retrieved_docs = self.search_knowledge(query)\n",
    "        print(f\"Retrieved {len(retrieved_docs)} relevant documents\")\n",
    "        \n",
    "        for i, doc in enumerate(retrieved_docs, 1):\n",
    "            print(f\"  Doc {i}: {doc['text'][:50]}...\")\n",
    "        \n",
    "        # Step 2: Generate answer\n",
    "        answer = self.generate_answer(query, retrieved_docs)\n",
    "        print(f\"Answer: {answer}\")\n",
    "        \n",
    "        return answer\n",
    "\n",
    "# Test RAG system\n",
    "rag_system = SimpleRAGSystem()\n",
    "\n",
    "print(\"RAG System Demo:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "test_queries = [\n",
    "    \"What is Python?\",\n",
    "    \"Tell me about machine learning\",\n",
    "    \"How do neural networks work?\",\n",
    "    \"What is quantum computing?\"  # Not in knowledge base\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\n\" + \"=\"*50)\n",
    "    rag_system.ask_question(query)\n",
    "\n",
    "# =============================================================================\n",
    "# PART 4: VECTOR EMBEDDINGS AND SEMANTIC SEARCH\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\\nPART 4: VECTOR EMBEDDINGS - SEMANTIC UNDERSTANDING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"Vector embeddings convert text into numerical vectors that capture meaning.\")\n",
    "print(\"Similar concepts have similar vectors, enabling semantic search.\")\n",
    "\n",
    "# Simulate text embeddings\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class SimpleEmbeddingSystem:\n",
    "    \"\"\"Simple text embedding system using TF-IDF\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.vectorizer = TfidfVectorizer(stop_words='english', max_features=100)\n",
    "        self.documents = []\n",
    "        self.embeddings = None\n",
    "    \n",
    "    def add_documents(self, docs):\n",
    "        \"\"\"Add documents to the system\"\"\"\n",
    "        self.documents = docs\n",
    "        # Create embeddings for all documents\n",
    "        self.embeddings = self.vectorizer.fit_transform(docs)\n",
    "        print(f\"Created embeddings for {len(docs)} documents\")\n",
    "        print(f\"Embedding dimension: {self.embeddings.shape[1]}\")\n",
    "    \n",
    "    def search_similar(self, query, top_k=3):\n",
    "        \"\"\"Find most similar documents to query\"\"\"\n",
    "        # Convert query to embedding\n",
    "        query_embedding = self.vectorizer.transform([query])\n",
    "        \n",
    "        # Calculate similarities\n",
    "        similarities = cosine_similarity(query_embedding, self.embeddings)[0]\n",
    "        \n",
    "        # Get top_k most similar\n",
    "        top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "        \n",
    "        results = []\n",
    "        for idx in top_indices:\n",
    "            if similarities[idx] > 0:  # Only return if there's some similarity\n",
    "                results.append({\n",
    "                    'document': self.documents[idx],\n",
    "                    'similarity': similarities[idx],\n",
    "                    'index': idx\n",
    "                })\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Test embedding system\n",
    "docs = [\n",
    "    \"Python is a programming language used for web development and data science\",\n",
    "    \"Machine learning algorithms can predict future outcomes from historical data\", \n",
    "    \"Neural networks are inspired by the human brain and used in deep learning\",\n",
    "    \"Data visualization helps us understand patterns in large datasets\",\n",
    "    \"Web development involves creating websites and web applications\",\n",
    "    \"Artificial intelligence aims to create machines that can think like humans\",\n",
    "    \"Statistics is the foundation of data analysis and machine learning\"\n",
    "]\n",
    "\n",
    "embedding_system = SimpleEmbeddingSystem()\n",
    "embedding_system.add_documents(docs)\n",
    "\n",
    "print(\"\\nSemantic Search Demo:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "test_queries = [\n",
    "    \"programming languages for data analysis\",\n",
    "    \"artificial intelligence and neural networks\", \n",
    "    \"statistical analysis of data\",\n",
    "    \"building websites\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\nQuery: '{query}'\")\n",
    "    results = embedding_system.search_similar(query, top_k=2)\n",
    "    \n",
    "    for i, result in enumerate(results, 1):\n",
    "        print(f\"  {i}. Similarity: {result['similarity']:.3f}\")\n",
    "        print(f\"     Document: {result['document']}\")\n",
    "\n",
    "# =============================================================================\n",
    "# PART 5: AI AGENTS - AUTONOMOUS AI SYSTEMS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\\nPART 5: AI AGENTS - AUTONOMOUS AI SYSTEMS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"AI Agents can:\")\n",
    "print(\"‚Ä¢ Make decisions based on goals\")\n",
    "print(\"‚Ä¢ Use tools and take actions\")\n",
    "print(\"‚Ä¢ Learn from experience\")\n",
    "print(\"‚Ä¢ Interact with environments\")\n",
    "\n",
    "# Simple AI agent that can use tools\n",
    "class SimpleAIAgent:\n",
    "    \"\"\"Basic AI agent with tool usage capabilities\"\"\"\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.tools = {\n",
    "            'calculator': self.calculator_tool,\n",
    "            'search': self.search_tool,\n",
    "            'translator': self.translator_tool\n",
    "        }\n",
    "        self.memory = []\n",
    "    \n",
    "    def calculator_tool(self, expression):\n",
    "        \"\"\"Simple calculator tool\"\"\"\n",
    "        try:\n",
    "            # Safe evaluation of basic math expressions\n",
    "            allowed_chars = set('0123456789+-*/(). ')\n",
    "            if not all(c in allowed_chars for c in expression):\n",
    "                return \"Error: Invalid characters in expression\"\n",
    "            \n",
    "            result = eval(expression)\n",
    "            return f\"Calculation result: {result}\"\n",
    "        except:\n",
    "            return \"Error: Invalid mathematical expression\"\n",
    "    \n",
    "    def search_tool(self, query):\n",
    "        \"\"\"Simulated search tool\"\"\"\n",
    "        # Simulate search results\n",
    "        search_results = {\n",
    "            'python': 'Python is a programming language created by Guido van Rossum',\n",
    "            'ai': 'Artificial Intelligence is the simulation of human intelligence in machines',\n",
    "            'weather': 'Current weather information would be retrieved from a weather API'\n",
    "        }\n",
    "        \n",
    "        for keyword in search_results:\n",
    "            if keyword in query.lower():\n",
    "                return f\"Search result: {search_results[keyword]}\"\n",
    "        \n",
    "        return \"Search result: No specific information found for this query\"\n",
    "    \n",
    "    def translator_tool(self, text):\n",
    "        \"\"\"Simulated translation tool\"\"\"\n",
    "        # Simple word translations\n",
    "        translations = {\n",
    "            'hello': 'hola (Spanish)',\n",
    "            'thank you': 'gracias (Spanish)', \n",
    "            'goodbye': 'adi√≥s (Spanish)'\n",
    "        }\n",
    "        \n",
    "        for english, translation in translations.items():\n",
    "            if english in text.lower():\n",
    "                return f\"Translation: {translation}\"\n",
    "        \n",
    "        return \"Translation: Translation not available for this phrase\"\n",
    "    \n",
    "    def parse_task(self, task):\n",
    "        \"\"\"Parse user task and determine which tool to use\"\"\"\n",
    "        task_lower = task.lower()\n",
    "        \n",
    "        if any(op in task_lower for op in ['+', '-', '*', '/', 'calculate', 'math']):\n",
    "            # Extract mathematical expression\n",
    "            import re\n",
    "            math_pattern = r'[\\d+\\-*/().\\s]+'\n",
    "            match = re.search(math_pattern, task)\n",
    "            if match:\n",
    "                return 'calculator', match.group().strip()\n",
    "        \n",
    "        elif any(word in task_lower for word in ['search', 'find', 'what is', 'tell me about']):\n",
    "            return 'search', task\n",
    "        \n",
    "        elif any(word in task_lower for word in ['translate', 'translation']):\n",
    "            return 'translator', task\n",
    "        \n",
    "        return None, task\n",
    "    \n",
    "    def execute_task(self, task):\n",
    "        \"\"\"Execute a task using appropriate tools\"\"\"\n",
    "        print(f\"{self.name}: Received task - '{task}'\")\n",
    "        \n",
    "        # Parse task to determine tool and input\n",
    "        tool_name, tool_input = self.parse_task(task)\n",
    "        \n",
    "        if tool_name and tool_name in self.tools:\n",
    "            print(f\"{self.name}: Using {tool_name} tool\")\n",
    "            result = self.tools[tool_name](tool_input)\n",
    "            self.memory.append({'task': task, 'tool': tool_name, 'result': result})\n",
    "            print(f\"{self.name}: {result}\")\n",
    "        else:\n",
    "            result = f\"I'm not sure how to help with that task. Available tools: {list(self.tools.keys())}\"\n",
    "            print(f\"{self.name}: {result}\")\n",
    "        \n",
    "        return result\n",
    "\n",
    "# Create and test AI agent\n",
    "agent = SimpleAIAgent(\"Assistant\")\n",
    "\n",
    "print(\"AI Agent Demo:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "test_tasks = [\n",
    "    \"Calculate 25 * 4 + 10\",\n",
    "    \"Search for information about Python\",\n",
    "    \"Translate hello to Spanish\",\n",
    "    \"What is 100 / 5?\",\n",
    "    \"Find information about artificial intelligence\",\n",
    "    \"Help me write a poem\"  # Task the agent can't handle\n",
    "]\n",
    "\n",
    "for task in test_tasks:\n",
    "    print(f\"\\n\" + \"=\"*50)\n",
    "    agent.execute_task(task)\n",
    "\n",
    "print(f\"\\nAgent Memory ({len(agent.memory)} tasks completed):\")\n",
    "for i, memory in enumerate(agent.memory, 1):\n",
    "    print(f\"{i}. Tool: {memory['tool']}, Task: {memory['task'][:30]}...\")\n",
    "\n",
    "# =============================================================================\n",
    "# PART 6: MULTI-MODAL AI (TEXT + IMAGES)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\\nPART 6: MULTI-MODAL AI - TEXT + IMAGES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"Multi-modal AI can understand and generate multiple types of content:\")\n",
    "print(\"‚Ä¢ Text + Images (like GPT-4 Vision)\")\n",
    "print(\"‚Ä¢ Text + Audio (like speech recognition)\")\n",
    "print(\"‚Ä¢ Text + Video (like video understanding)\")\n",
    "\n",
    "# Simulate a multi-modal AI system\n",
    "class SimpleMultiModalAI:\n",
    "    \"\"\"Simulated multi-modal AI that processes text and images\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.image_categories = {\n",
    "            'high_contrast': 'This appears to be a high-contrast image, possibly containing text or clear shapes',\n",
    "            'low_contrast': 'This appears to be a low-contrast image, possibly a photograph or natural scene',\n",
    "            'geometric': 'This image contains geometric patterns or shapes',\n",
    "            'random': 'This appears to be a random or noisy image'\n",
    "        }\n",
    "    \n",
    "    def analyze_image(self, image_array):\n",
    "        \"\"\"Analyze image and return description\"\"\"\n",
    "        # Simple image analysis based on statistical properties\n",
    "        mean_intensity = np.mean(image_array)\n",
    "        std_intensity = np.std(image_array)\n",
    "        \n",
    "        # Classify based on simple heuristics\n",
    "        if std_intensity > 0.3:\n",
    "            category = 'high_contrast'\n",
    "        elif std_intensity < 0.1:\n",
    "            category = 'low_contrast'  \n",
    "        elif mean_intensity > 0.7:\n",
    "            category = 'geometric'\n",
    "        else:\n",
    "            category = 'random'\n",
    "        \n",
    "        analysis = {\n",
    "            'category': category,\n",
    "            'description': self.image_categories[category],\n",
    "            'mean_intensity': mean_intensity,\n",
    "            'contrast': std_intensity,\n",
    "            'size': image_array.shape\n",
    "        }\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def process_text_and_image(self, text_query, image_array):\n",
    "        \"\"\"Process both text and image together\"\"\"\n",
    "        # Analyze image\n",
    "        image_analysis = self.analyze_image(image_array)\n",
    "        \n",
    "        # Generate response based on text query and image analysis\n",
    "        if 'describe' in text_query.lower():\n",
    "            response = f\"I can see an image that is {image_analysis['description'].lower()}. \"\n",
    "            response += f\"It has dimensions {image_analysis['size']} with average intensity {image_analysis['mean_intensity']:.2f}.\"\n",
    "        \n",
    "        elif 'what' in text_query.lower() and 'see' in text_query.lower():\n",
    "            response = f\"I see a {image_analysis['category'].replace('_', ' ')} image. {image_analysis['description']}\"\n",
    "        \n",
    "        else:\n",
    "            response = f\"Based on the image analysis: {image_analysis['description']}\"\n",
    "        \n",
    "        return response, image_analysis\n",
    "\n",
    "# Test multi-modal AI\n",
    "multimodal_ai = SimpleMultiModalAI()\n",
    "\n",
    "# Create test images\n",
    "test_images = {\n",
    "    'High Contrast': np.random.choice([0, 1], size=(10, 10)),  # Binary image\n",
    "    'Low Contrast': np.random.normal(0.5, 0.05, size=(10, 10)),  # Low variance\n",
    "    'Geometric': np.zeros((10, 10))  # Will be modified to create patterns\n",
    "}\n",
    "\n",
    "# Create geometric pattern\n",
    "test_images['Geometric'][2:8, 2:8] = 1  # Square in the middle\n",
    "\n",
    "print(\"Multi-Modal AI Demo:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "test_queries = [\n",
    "    \"Describe what you see in this image\",\n",
    "    \"What can you tell me about this picture?\",\n",
    "    \"Analyze the visual content\"\n",
    "]\n",
    "\n",
    "for img_name, img_array in test_images.items():\n",
    "    print(f\"\\nTesting with {img_name} image:\")\n",
    "    \n",
    "    # Visualize the test image\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    plt.imshow(img_array, cmap='gray')\n",
    "    plt.title(f'{img_name} Test Image')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    query = test_queries[0]  # Use first query for demo\n",
    "    response, analysis = multimodal_ai.process_text_and_image(query, img_array)\n",
    "    \n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Response: {response}\")\n",
    "    print(f\"Technical analysis: Mean={analysis['mean_intensity']:.3f}, Contrast={analysis['contrast']:.3f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# SUMMARY AND NEXT STEPS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\\nSUMMARY: MODERN AI APPLICATIONS MASTERED\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "‚úÖ Core AI Concepts:\n",
    "   ‚Ä¢ Large Language Models (LLMs) and text generation\n",
    "   ‚Ä¢ Prompt engineering for effective AI communication\n",
    "   ‚Ä¢ Retrieval Augmented Generation (RAG) systems\n",
    "   ‚Ä¢ Vector embeddings and semantic search\n",
    "   ‚Ä¢ AI agents with tool usage capabilities\n",
    "   ‚Ä¢ Multi-modal AI (text + images)\n",
    "\n",
    "‚úÖ Practical Systems Built:\n",
    "   ‚Ä¢ Simple language model with word prediction\n",
    "   ‚Ä¢ RAG system for document question-answering\n",
    "   ‚Ä¢ Embedding-based semantic search engine\n",
    "   ‚Ä¢ AI agent that can use multiple tools\n",
    "   ‚Ä¢ Multi-modal AI for text and image processing\n",
    "\n",
    "‚úÖ Real-World Applications:\n",
    "   ‚Ä¢ Document Q&A systems (like ChatPDF)\n",
    "   ‚Ä¢ Semantic search engines\n",
    "   ‚Ä¢ AI assistants with tool access\n",
    "   ‚Ä¢ Content generation and analysis\n",
    "   ‚Ä¢ Knowledge retrieval systems\n",
    "\n",
    "‚úÖ Technical Skills:\n",
    "   ‚Ä¢ Understanding transformer architectures\n",
    "   ‚Ä¢ Building RAG pipelines\n",
    "   ‚Ä¢ Implementing semantic search\n",
    "   ‚Ä¢ Creating AI agents with tool usage\n",
    "   ‚Ä¢ Processing multiple data modalities\n",
    "\n",
    "üéØ Industry Applications:\n",
    "   ‚Ä¢ Customer service chatbots\n",
    "   ‚Ä¢ Document analysis systems\n",
    "   ‚Ä¢ Code generation assistants\n",
    "   ‚Ä¢ Research and knowledge management\n",
    "   ‚Ä¢ Content creation and editing tools\n",
    "\n",
    "üöÄ Next Steps:\n",
    "   ‚Ä¢ Explore real LLM APIs (OpenAI, Anthropic, Hugging Face)\n",
    "   ‚Ä¢ Build production RAG systems with vector databases\n",
    "   ‚Ä¢ Learn about fine-tuning and model customization\n",
    "   ‚Ä¢ Understand AI safety and alignment\n",
    "   ‚Ä¢ Create full-stack AI applications\n",
    "\"\"\")\n",
    "\n",
    "print(\"üéâ Congratulations! You now understand modern AI systems!\")\n",
    "print(\"You have the foundation to build cutting-edge AI applications!\")\n",
    "print(\"From machine learning basics to modern AI agents - you've mastered the full spectrum!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e053d6b",
   "metadata": {},
   "source": [
    "## RAG System Implementation\n",
    "\n",
    "Build a Retrieval Augmented Generation system for question answering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771628e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your RAG system code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c9d21d",
   "metadata": {},
   "source": [
    "## AI Agent Framework\n",
    "\n",
    "Design and implement an autonomous AI agent that can perform tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e315dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your AI agent code here"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
